---
title: Python爬虫-1.开发环境配置【完善中...】
date: 2023-06-10
keywords: 爬虫 库安装
top_img: D:/Blog/source/_posts/img/springday

---

> 第一次装到tesserocr就累了╯︿╰，一开始根本不需要用装这么多  --2023.6.10  13:58:2

# 请求库的安装

## requests安装

- `pip3 install requests`
- 用于发送 HTTP 请求和处理响应
- 可以方便地进行 GET、POST 等请求，设置请求头、请求参数、处理响应结果等操作。
- 验证安装：进入python 输入`import requests`，如无错误提示即成功

## selenium安装

- `pip3 install selenium`
- 模拟用户在浏览器中的操作,包括点击、输入、提交表单等
- 可以驱动真实的浏览器（如 Chrome、Firefox）来加载动态生成的网页内容，并提取或交互其中的数据。通常与浏览器驱动配合使用，如 ChromeDriver 和 GeckoDriver。
- 验证安装：同上

## ChromeDriver 安装

- 浏览器驱动,用于控制 Chrome  浏览器的行为

- 作用：让 `selenium` 可以控制和与指定的浏览器进行交互

- https://sites.google.com/a/chromium.org/chromedriver  --exe文件放入环境变量配置

- GeckoDriver 安装  --适用于 Firefox

- 验证安装：

  - 环境变量：终端输入`chromedriver`

  - 使用：  打开浏览器

    ```python
    from selenium import webdriver
    browser = webdriver.Chrome()
    ```

  - 出现闪退计版本出现问题【但是我在其他代码上用又不会闪退🤔--待解决】

## PhantomJS安装  【不维护了】

- 无界面的浏览器

- 在后台执行网页加载和操作，无需显示浏览器界面

- http://phantomjs.org/download.html  --放入环境变量配置

- 验证安装

  - 环境变量：终端输入`phantomjs`

  - 使用

    ```python
    from selenium import webdriver
    browser = webdriver.PhantomJS()
    browser.get('https://www.baidu.com')
    print(browser.current_url)
    ```

  - 报错显示`module 'selenium.webdriver' has no attribute 'PhantomJS'`    --由于维护困难和性能问题，Selenium 社区决定不再支持 PhantomJS 驱动。

  - 推荐使用无头浏览器（如 Chrome 或 Firefox）的 Headless 模式替代。

    ```python
    from selenium import webdriver
    from selenium.webdriver.chrome.options import Options
    
    # 创建 ChromeOptions 对象，并设置无界面模式
    chrome_options = Options()
    chrome_options.add_argument('--headless')  # 启用无界面模式
    
    # 创建 Chrome WebDriver，将 ChromeOptions 作为参数传递
    browser = webdriver.Chrome(options=chrome_options)
    
    browser.get('https://www.baidu.com')
    print(browser.current_url)
    
    browser.quit()  # 关闭浏览器
    
    ```

    

## aiohttp的安装

- `pip3 install aiohttp`   +   `pip3 install cchardet aiodns`
  - 字符编码检测库 cchardet
  - 加速 DNS 的解析库 aiodns
- 基于异步请求的 HTTP 客户端/服务器框架，适用于高性能、高并发的网络请求场景
- 在处理大规模异步请求时具有优势，可以加快网络爬虫的速度。
- 验证安装：进入python输入`import aiohttp`，如无错误提示即成功

# 解析库的安装

## lxml 的安装

- `pip3 install lxml`
- 支持 HTML 和 XML 的解析，支持 XPath 解析方式，而且解析效率非常高
- 验证安装：进入python 输入`import lxml`，如无错误提示即成功

## Beautiful Soup 的安装

- `pip3 install beautifulsoup4`

- HTML 或 XML 的解析库，我们可以用它来方便地从网页中提取数据。它拥有强大的 API 和多样的解析方式

- 验证安装

  ```python
  from bs4 import BeautifulSoup  
  soup = BeautifulSoup('&lt;p&gt;Hello&lt;/p&gt;', 'lxml')  
  print(soup.p.string)
  # 输出hello即成功
  ```

## pyquery 的安装

- `pip3 install pyquery`
- 强大的网页解析工具，它提供了和 jQuery 类似的语法来解析 HTML 文档，支持 CSS 选择器
- 验证安装：进入python输入`import pyquery`，如无错误提示即成功

## tesserocr 的安装

- http://digi.bib.uni-mannheim.de/tesseract 下载不带 dev 的版本   + `pip3 install tesserocr pillow`
- 用 OCR 来识别图形验证码

# 数据库的安装

## MySQL 的安装

[MySQL安装配置教程（超级详细、保姆级）_mysql安装教程_SoloVersion的博客-CSDN博客](https://blog.csdn.net/SoloVersion/article/details/123760428)

## MongoDB 的安装

## Redis 的安装

# 存储库的安装

## PyMySQL  的安装

## PyMongo 的安装

## redis-py 的安装

## RedisDump 的安装

# Web 库的安装

##  Flask 的安装

## Tornado 的安装

# App 爬取相关库的安装

## Charles 的安装

## mitmproxy 的安装

## Appium 的安装

# 爬虫框架的安装

## pyspider 的安装

## Scrapy 的安装

## Scrapy-Splash 的安装

## Scrapy-Redis 的安装

# 部署相关库的安装

## Docker 的安装

## Scrapyd 的安装

## Scrapyd-Client 的安装

## Scrapyd API 的安装

## Scrapyrt 的安装

## Gerapy 的安装

